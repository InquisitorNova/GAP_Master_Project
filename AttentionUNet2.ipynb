{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jul 12 12:31:09 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 546.92                 Driver Version: 546.92       CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4080 ...  WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "| N/A   47C    P8               4W / 130W |    844MiB / 12282MiB |      8%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      1000    C+G   ...\\AppData\\Local\\Grindstone 4\\GS4.exe    N/A      |\n",
      "|    0   N/A  N/A      1652    C+G   ...App\\OmenCommandCenterBackground.exe    N/A      |\n",
      "|    0   N/A  N/A      6632    C+G   ...2101_x64__8wekyb3d8bbwe\\msteams.exe    N/A      |\n",
      "|    0   N/A  N/A     10632    C+G   ...\\cef\\cef.win7x64\\steamwebhelper.exe    N/A      |\n",
      "|    0   N/A  N/A     11624    C+G   ...ograms\\cron-web\\Notion Calendar.exe    N/A      |\n",
      "|    0   N/A  N/A     11828    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe    N/A      |\n",
      "|    0   N/A  N/A     18488    C+G   ...on\\126.0.2592.87\\msedgewebview2.exe    N/A      |\n",
      "|    0   N/A  N/A     19100    C+G   ...ta\\Local\\Programs\\Notion\\Notion.exe    N/A      |\n",
      "|    0   N/A  N/A     19508    C+G   ...les\\Microsoft OneDrive\\OneDrive.exe    N/A      |\n",
      "|    0   N/A  N/A     21888    C+G   ...89.0_x64__v10z8vjag6ke6\\HP.myHP.exe    N/A      |\n",
      "|    0   N/A  N/A     23548    C+G   ...367_x64__8wekyb3d8bbwe\\ms-teams.exe    N/A      |\n",
      "|    0   N/A  N/A     24916    C+G   ...ekyb3d8bbwe\\PhoneExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     25208    C+G   ...\\cef\\cef.win7x64\\steamwebhelper.exe    N/A      |\n",
      "|    0   N/A  N/A     25488    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A     25940    C+G   ...siveControlPanel\\SystemSettings.exe    N/A      |\n",
      "|    0   N/A  N/A     26460    C+G   ...on\\126.0.2592.87\\msedgewebview2.exe    N/A      |\n",
      "|    0   N/A  N/A     30312    C+G   ...42.0_x64__8wekyb3d8bbwe\\GameBar.exe    N/A      |\n",
      "|    0   N/A  N/A     31116    C+G   ...__8wekyb3d8bbwe\\WindowsTerminal.exe    N/A      |\n",
      "|    0   N/A  N/A     31480    C+G   ...Brave-Browser\\Application\\brave.exe    N/A      |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import scipy as sp \n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch.nn import init\n",
    "import pytorch_lightning as pL\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Device Being Used:\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "# Define the relevant helper functions for the attention UNet architecture\n",
    "def conv1x1(in_channels, out_channels, stride=1):\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "def conv3x3(in_channels, out_channels, stride = 1):\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "\n",
    "def Swish():\n",
    "    return nn.SiLU()\n",
    "\n",
    "def GeLU():\n",
    "    return nn.GELU()\n",
    "\n",
    "def Mish():\n",
    "    return nn.Mish()\n",
    "\n",
    "def Sigmoid():\n",
    "    return nn.Sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transformation for converting psnr into timesteps.\n",
    "def psnr_to_timestep(psnr, minpsnr, maxpsnr, num_timesteps):\n",
    "    \"\"\"\n",
    "    psnr - the psnr value to convert to a timestep\n",
    "    minpsnr - the minimum psnr value that can be achieved\n",
    "    maxpsnr - the maximum psnr value that can be achieved\n",
    "    num_timesteps - the number of timesteps in the simulation\n",
    "    This function takes a psnr as import, performs min-max normalisation and \n",
    "    then converts it into a timestep.\n",
    "    \"\"\"\n",
    "    psnr = torch.FloatTensor([psnr])\n",
    "    minpsnr = torch.FloatTensor([minpsnr])\n",
    "    maxpsnr = torch.FloatTensor([maxpsnr])\n",
    "    \n",
    "    psnr = torch.maximum(torch.minimum(psnr, maxpsnr), minpsnr)\n",
    "    normalised_psnr = ((psnr - minpsnr) / (maxpsnr - minpsnr))\n",
    "    timestep = (num_timesteps-1)*normalised_psnr\n",
    "    return torch.Tensor([timestep]).to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transformation for converting the timestep into a positional embedding.\n",
    "class Temporal_Embedder(nn.Module):\n",
    "    def __init__(self, n_channels):\n",
    "        super(Temporal_Embedder, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.Linear_1 = nn.Linear(self.n_channels//4, self.n_channels)\n",
    "        self.Linear_2 = nn.Linear(self.n_channels, self.n_channels)\n",
    "        self.Mish_1 = Mish()\n",
    "        self.Mish_2 = Mish()\n",
    "\n",
    "    def forward(self, t):\n",
    "        half_dim = self.n_channels//8\n",
    "        constant = torch.FloatTensor([10000.0])\n",
    "        emb = torch.log(constant) / (half_dim -1)\n",
    "        emb = torch.exp(torch.arange(half_dim) * -emb)\n",
    "        emb = t[:, None] * emb[None, :]\n",
    "        emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim = 1)\n",
    "        emb = emb.to(device)\n",
    "        \n",
    "        emb = self.Mish_1(self.Linear_1(emb))\n",
    "        emb = self.Mish_2(self.Linear_2(emb))\n",
    "        return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Squeeze and Extraction Block used to recaliberate feature maps from a convolution.\n",
    "class SEblock(nn.Module):\n",
    "    def __init__(self, units, bottlenecks, dropout_rate):\n",
    "        super(SEblock, self).__init__()\n",
    "        \n",
    "        self.units = units\n",
    "        self.bottlenecks = bottlenecks\n",
    "        self.dropout_rate = dropout_rate\n",
    "        \n",
    "        # Define the SE Block layers\n",
    "        self.Dense = nn.LazyLinear(units)\n",
    "        self.Dropout = nn.Dropout2d(dropout_rate)\n",
    "        self.GlobalPool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.GlobalPool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.Dense(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = self.Dense_2(x)\n",
    "        x = F.sigmoid(x)\n",
    "        x = x.view(-1, self.units, 1, 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Different Convolution Blocks for the Encoder and Decoder\n",
    "class Residual_Block(nn.Module):\n",
    "    \"\"\"\n",
    "    in_channels = Number of Incoming Channels\n",
    "    out_channels = Number of Outgoing Channels\n",
    "    time_channels = Number of Time Channels\n",
    "    dropout_rate = Dropout Rate\n",
    "    n_groups = Number of Groups\n",
    "    stride = Stride\n",
    "    This Block is the traditional residual block used in standard diffusion models.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, time_channels,\n",
    "                dropout_rate, n_groups = 8, stride=1):\n",
    "        \n",
    "        super(Residual_Block, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.stride = stride\n",
    "        self.n_groups = n_groups\n",
    "        self.time_channels = time_channels\n",
    "\n",
    "        # Define the residual block layers\n",
    "\n",
    "        self.time_embedding = nn.Linear(time_channels, out_channels)\n",
    "        self.conv1 = conv3x3(in_channels, out_channels)\n",
    "        self.conv2 = conv3x3(out_channels, out_channels)\n",
    "        self.conv3 = conv1x1(in_channels, out_channels)\n",
    "\n",
    "        self.GroupNorm_1 = nn.GroupNorm(n_groups, in_channels)\n",
    "        self.GroupNorm_2 = nn.GroupNorm(n_groups, out_channels)\n",
    "        self.Batch_Norm_1 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.dropout_1 = nn.Dropout(dropout_rate)\n",
    "        self.dropout_2 = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.Mish_1 = Mish()\n",
    "        self.Mish_2 = Mish()\n",
    "        self.Mish_3 = Mish()\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        x_skip = self.Batch_Norm_1(self.conv3(x))\n",
    "        \n",
    "        x = self.conv1(self.Mish_1(self.GroupNorm_1(x)))\n",
    "        x = self.dropout_1(x)\n",
    "\n",
    "        h = self.Mish_3(self.time_embedding(t)[:,:,None,None])\n",
    "        x += h\n",
    "\n",
    "        x = self.conv2(self.Mish_2(self.GroupNorm_2(x)))\n",
    "        x = self.dropout_2(x)\n",
    "        x += x_skip\n",
    "    \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Efficient_Residual_Block(nn.Module):\n",
    "    \"\"\"\n",
    "    in_channels = Number of incoming channels\n",
    "    out_channels = Number of outgoing channels\n",
    "    time_channels = Number of time channels\n",
    "    dropout_rate = Dropout Rate\n",
    "    n_groups = Number of Groups\n",
    "    bottleneck_channels = Number of channels in the Convolution Bottleneck\n",
    "    stride = Stride\n",
    "    This block is a computational efficient variant of the residual block used \n",
    "    in standard diffusion models. It increases the computational efficiency, by performing\n",
    "    the 3v3 convolution in a reduced channel space before restoring the dimensionality of the \n",
    "    feature representation.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, bottleneck_channels, time_channels, \n",
    "                 out_channels, dropout_rate, n_groups = 8, stride=1):\n",
    "        \n",
    "        super(Efficient_Residual_Block, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.stride = stride\n",
    "        self.n_groups =  n_groups\n",
    "        self.time_channels = time_channels\n",
    "\n",
    "        # Define the residual block layers\n",
    "\n",
    "        self.time_embedding = nn.Linear(time_channels, bottleneck_channels)\n",
    "        self.conv1 = conv1x1(in_channels, bottleneck_channels)\n",
    "        self.conv2 = conv3x3(bottleneck_channels, bottleneck_channels)\n",
    "        self.conv3 = conv1x1(bottleneck_channels, out_channels)\n",
    "\n",
    "        self.GroupNorm_1 = nn.GroupNorm(self.n_groups, in_channels)\n",
    "        self.GroupNorm_2 = nn.GroupNorm(self.n_groups, bottleneck_channels)\n",
    "        self.GroupNorm_2 = nn.GroupNorm(self.n_groups, out_channels)\n",
    "        self.Batch_Norm_1 = nn.BatchNorm2d(in_channels)\n",
    "\n",
    "        self.dropout_1 = nn.Dropout2d(dropout_rate)\n",
    "        self.dropout_2 = nn.Dropout2d(dropout_rate)\n",
    "        self.dropout_3 = nn.Dropout2d(dropout_rate)\n",
    "\n",
    "        self.Mish_1 = Mish()\n",
    "        self.Mish_2 = Mish()\n",
    "        self.Mish_3 = Mish()\n",
    "        self.Mish_4 = Mish()\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        x_skip = self.Batch_Norm_1(self.conv3(x))\n",
    "        \n",
    "        x = self.conv1(self.Mish_1(self.GroupNorm_1(x)))\n",
    "        x = self.dropout_1(x)\n",
    "\n",
    "        x = self.conv2(self.Mish_2(self.GroupNorm_2(x)))\n",
    "        x = self.dropout_2(x)\n",
    "\n",
    "        h = self.Mish_4(self.time_embedding(t)[:,:, None, None])\n",
    "        x += h\n",
    "\n",
    "        x = self.conv3(self.Mish_3(self.GroupNorm_3(x)))\n",
    "        x = self.dropout_3(x)\n",
    "\n",
    "        x += x_skip\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SqueezeExtraction_Block(nn.Module):\n",
    "    \"\"\"\n",
    "    filters = The number of outgoing channels\n",
    "    units = The number of units in the SE block\n",
    "    dropout_rate = The dropout rate\n",
    "    time_channels = The number of time channels\n",
    "    units_bottleneck = The number of units in the bottleneck of the SE Block\n",
    "    n_groups = The number of groups in the Group Normalisation\n",
    "    This block is a variant of the residual block used in standard diffusion models.\n",
    "    It incorporates the squeeze and extraction blocks to recaliberate the feature maps \n",
    "    coming from the convolutions.\n",
    "    \"\"\"\n",
    "    def __init__(self, filters, units, dropout_rate,\n",
    "                 time_channels, units_bottleneck, n_groups = 8):\n",
    "        super(SqueezeExtraction_Block, self).__init__()\n",
    "        \n",
    "        self.filters = filters\n",
    "        self.units = units\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.units_bottleneck = units_bottleneck\n",
    "        self.time_channels = time_channels\n",
    "        self.n_groups = n_groups\n",
    "        \n",
    "        # Define the SqueezeExtraction_Block Layers\n",
    "        \n",
    "        self.time_embedding = nn.Linear(time_channels, filters)\n",
    "        self.Conv_1 = nn.LazyConv2d(filters, 3, padding = 1, stride = 1)\n",
    "        self.Conv_2 = nn.LazyConv2d(filters, 3, padding = 1, stride = 1)\n",
    "        self.Conv_Bypass = nn.LazyConv2d(filters, 1)\n",
    "\n",
    "        self.GroupNorm_1 = nn.GroupNorm(8, filters)\n",
    "        self.GroupNorm_2 = nn.GroupNorm(8, filters)\n",
    "\n",
    "        self.dropout_1 = nn.Dropout(dropout_rate)\n",
    "        self.dropout_2 = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.Mish_1 = Mish()\n",
    "        self.Mish_2 = Mish()\n",
    "        self.Mish_3 = Mish()\n",
    "        self.SE_Block = SEblock(units, units_bottleneck, dropout_rate)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        x_skip = self.Conv_Bypass(x)\n",
    "\n",
    "        x = self.Conv_1(self.Mish_1(self.GroupNorm_1(x)))\n",
    "        x = self.dropout_1(x)\n",
    "\n",
    "        h = self.Mish_3(self.time_embedding(x)[:,:,None,None])\n",
    "        y += h\n",
    "\n",
    "        x = self.Conv_2(self.Mish_2(self.GroupNorm_2(t)))\n",
    "        x = self.dropout_2(x)\n",
    "\n",
    "        y = self.SE_Block(x)\n",
    "        y *= x\n",
    "        x = y + x_skip\n",
    "\n",
    "        x = F.leaky_relu(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualDense_Block(nn.Module):\n",
    "    \"\"\"\n",
    "    in_channels = Number of incoming channels\n",
    "    out_channels = Number of Outgoing channels\n",
    "    dropout_rate = dropout_rate\n",
    "    time_channels = Number of time channels\n",
    "    n_groups = Number of groups in the group normalisation layer\n",
    "    This block is a variant of the residual block used in standard diffusion models.\n",
    "    The block incorporates dense connections between the convolutional layers to increase\n",
    "    computational efficiency by incentising feature reuse. Skip connections continue to be \n",
    "    used to create a hybrid between a residual an dense connection design.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, dropout_rate,\n",
    "                time_channels, n_groups = 8):\n",
    "        super(ResidualDense_Block, self).__init__()\n",
    "        \n",
    "        self.in_channels = in_channels\n",
    "        self.in_out_channels = out_channels\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.n_groups = n_groups\n",
    "        \n",
    "        # Define the Fully_Dense_Encoder layers\n",
    "\n",
    "        self.time_embedding = nn.Linear(time_channels, out_channels)\n",
    "\n",
    "        self.conv1 = nn.LazyConv2d(out_channels, kernel_size=3, padding=1, stride=1)\n",
    "        self.conv2 = nn.LazyConv2d(out_channels, kernel_size=3, padding=1, stride=1)\n",
    "        self.conv3 = nn.LazyConv2d(out_channels, kernel_size=3, padding=1, stride=1)\n",
    "        self.conv4 = nn.LazyConv2d(out_channels, kernel_size=1, padding = 0, stride=1)\n",
    "        self.conv5 = nn.LazyConv2d(out_channels, kernel_size=1, padding = 0, stride=1)\n",
    "\n",
    "\n",
    "        self.GroupNorm_1 = nn.GroupNorm(self.n_groups, in_channels)\n",
    "        self.GroupNorm_2 = nn.GroupNorm(self.n_groups, in_channels + out_channels)\n",
    "        self.GroupNorm_3 = nn.GroupNorm(self.n_groups, in_channels + 2*out_channels)\n",
    "        self.BatchNorm_1 = nn.BatchNorm2d(in_channels)\n",
    "\n",
    "        self.Mish_1 = Mish()\n",
    "        self.Mish_2 = Mish()\n",
    "        self.Mish_3 = Mish()\n",
    "        self.Mish_4 = Mish()\n",
    "        self.Mish_5 = Mish()\n",
    "\n",
    "        self.dropout_1 = nn.Dropout2d(dropout_rate)\n",
    "        self.dropout_2 = nn.Dropout2d(dropout_rate)\n",
    "        self.dropout_3 = nn.Dropout2d(dropout_rate)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        x_cat, x_skip = x, self.BatchNorm_1(self.conv4(x))\n",
    "\n",
    "        x = self.conv1(self.Mish_1(self.GroupNorm_1(x)))\n",
    "        x = self.dropout_1(x)\n",
    "        x = torch.cat((x, x_cat), 1)\n",
    "\n",
    "        x_cat = x\n",
    "        x = self.conv2(self.Mish_2(self.GroupNorm_2(x)))\n",
    "        x = self.dropout_2(x)\n",
    "        x = torch.cat((x, x_cat), 1)\n",
    "\n",
    "        x_cat = x\n",
    "        h = self.Mish_5(self.time_embedding(t)[:,:, None, None])\n",
    "        x += h\n",
    "        x = self.conv3(self.Mish_3(self.GroupNorm_3(x)))\n",
    "        x = self.dropout_3(x)\n",
    "        x = torch.cat((x, x_cat), 1)\n",
    "\n",
    "\n",
    "        x = self.Mish_4(self.conv5(x))\n",
    "        x += x_skip\n",
    "\n",
    "        return x      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionBlock(nn.Module):\n",
    "    def __init__(self, n_channels, n_heads, dim_k, n_groups, dropout_rate):\n",
    "        super(AttentionBlock, self).__init__()\n",
    "\n",
    "        self.n_channels = n_channels\n",
    "        self.n_heads = n_heads\n",
    "        self.dim_k = dim_k\n",
    "        self.n_groups = n_groups\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.scale = dim_k ** -0.5\n",
    "\n",
    "        self.qkv = nn.Linear(n_channels, n_heads * dim_k * 3)\n",
    "        self.output = nn.Linear(n_heads*dim_k, n_channels)\n",
    "        self.norm = nn.GroupNorm(n_groups, n_channels)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, n_channels, height, width = x.shape\n",
    "        x = x.view(batch_size, n_channels, -1)\n",
    "        x_skip = x\n",
    "        x= x.permute(0,2,1)\n",
    "\n",
    "        qkv = self.qkv(x).view(batch_size, -1, self.n_heads, 3*self.dim_k)\n",
    "\n",
    "        q, k, v = qkv.chunk(3, dim=-1)\n",
    "\n",
    "        attn = torch.einsum(\"b h i d, b h j d -> b h i j\", q, k) * self.scale\n",
    "        attn = attn.softmax(dim = -1)\n",
    "        attn_output = torch.einsum(\"b h i j, b h j d -> b h i d\", attn, v)\n",
    "         \n",
    "        attn_output = attn_output.view(batch_size, -1, self.n_heads * self.dim_k)\n",
    "        attn_output = self.dropout(self.output(attn_output))\n",
    "        #print(attn_output.shape, x_skip.shape)\n",
    "        \n",
    "        attn_output = attn_output.permute(0,2,1)\n",
    "        attn  = self.norm(attn_output + x_skip)\n",
    "        attn_output = attn.view(batch_size, n_channels, height, width)\n",
    "        return attn_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroupQueryAttentionBlock(nn.Module):\n",
    "    def __init__(self, n_channels, n_heads, dim_k, n_groups, dropout_rate, group_size):\n",
    "        super(GroupQueryAttentionBlock, self).__init__()\n",
    "\n",
    "        self.n_channels = n_channels\n",
    "        self.n_heads = n_heads\n",
    "        self.dim_k = dim_k\n",
    "        self.n_groups = n_groups\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.scale = dim_k ** -0.5\n",
    "        self.group_size = group_size\n",
    "\n",
    "        self.qkv = nn.Linear(n_channels, n_heads * dim_k * 3)\n",
    "        self.output = nn.Linear(n_heads*dim_k, n_channels)\n",
    "        self.norm = nn.GroupNorm(n_groups, n_channels)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, n_channels, height, width = x.shape\n",
    "        x = x.view(batch_size, n_channels, -1)\n",
    "        x_skip = x\n",
    "        x= x.permute(0,2,1)\n",
    "\n",
    "        qkv = self.qkv(x).view(batch_size, -1, self.n_heads, 3*self.dim_k)\n",
    "\n",
    "        q, k, v = qkv.chunk(3, dim=-1)\n",
    "\n",
    "        num_groups = max(1, q.shape[1]//self.group_size)\n",
    "        #print(num_groups, q.shape[1], self.group_size)\n",
    "\n",
    "        q_groups = q.view(batch_size, num_groups, self.group_size, self.n_heads, self.dim_k)\n",
    "        k_groups = k.view(batch_size, num_groups, self.group_size, self.n_heads, self.dim_k)\n",
    "        v_groups = v.view(batch_size, num_groups, self.group_size, self.n_heads, self.dim_k)\n",
    "\n",
    "        attn_weights = torch.einsum(\"bgnhd, bgnhd -> bgnh\", q_groups, k_groups) * self.scale\n",
    "        attn_weights = F.softmax(attn_weights, dim = -1)\n",
    "        attn_output = torch.einsum(\"bgnh, bgnhd -> bgnhd\", attn_weights, v_groups)\n",
    "        \n",
    "        attn_output = attn_output.view(batch_size, -1, self.n_heads * self.dim_k)\n",
    "        attn_output = self.dropout(self.output(attn_output))\n",
    "        #print(attn_output.shape, x_skip.shape)\n",
    "        attn_output = attn_output.permute(0,2,1)\n",
    "        attn  = self.norm(attn_output + x_skip)\n",
    "        attn_output = attn.view(batch_size, n_channels, height, width)\n",
    "        return attn_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvGroupQueryAttentionBlock(nn.Module):\n",
    "    def __init__(self, n_channels, n_heads, dim_k, n_groups, dropout_rate, group_size, reduction_factor):\n",
    "        super(ConvGroupQueryAttentionBlock, self).__init__()\n",
    "\n",
    "        self.original_n_channels = n_channels\n",
    "        self.n_heads = n_heads\n",
    "        self.dim_k = dim_k\n",
    "        self.n_groups = n_groups\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.scale = dim_k ** -0.5\n",
    "        self.group_size = group_size\n",
    "        self.reduction_factor = reduction_factor\n",
    "        self.n_channels = n_channels//reduction_factor\n",
    "\n",
    "        self.bottleneck = nn.LazyConv2d(self.original_n_channels//reduction_factor, kernel_size= 1)\n",
    "        self.unbottleneck = nn.LazyConv2d(self.original_n_channels, kernel_size = 1)\n",
    "\n",
    "        self.qkv = nn.LazyLinear(n_heads * dim_k * 3)\n",
    "        self.output = nn.Linear(n_heads * dim_k, self.n_channels)\n",
    "        self.norm = nn.GroupNorm(n_groups, self.n_channels)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.bottleneck(x)\n",
    "        \n",
    "        batch_size, n_channels, height, width = x.shape\n",
    "        x = x.view(batch_size, n_channels, -1)\n",
    "        x_skip = x\n",
    "\n",
    "        x = x.permute(0,2,1)\n",
    "\n",
    "        qkv = self.qkv(x).view(batch_size, -1, self.n_heads, 3*self.dim_k)\n",
    "\n",
    "        q, k, v = qkv.chunk(3, dim=-1)\n",
    "\n",
    "        num_groups = max(1, q.shape[1]//self.group_size)\n",
    "        #print(num_groups, q.shape[1], self.group_size)\n",
    "\n",
    "        q_groups = q.view(batch_size, num_groups, self.group_size, self.n_heads, self.dim_k)\n",
    "        k_groups = k.view(batch_size, num_groups, self.group_size, self.n_heads, self.dim_k)\n",
    "        v_groups = v.view(batch_size, num_groups, self.group_size, self.n_heads, self.dim_k)\n",
    "\n",
    "        attn_weights = torch.einsum(\"bgnhd, bgnhd -> bgnh\", q_groups, k_groups) * self.scale\n",
    "        attn_weights = F.softmax(attn_weights, dim = -1)\n",
    "        attn_output = torch.einsum(\"bgnh, bgnhd -> bgnhd\", attn_weights, v_groups)\n",
    "        \n",
    "        attn_output = attn_output.view(batch_size, -1, self.n_heads * self.dim_k)\n",
    "        attn_output = self.dropout(self.output(attn_output))\n",
    "        #print(attn_output.shape, x_skip.shape)\n",
    "        attn_output = attn_output.permute(0,2,1)\n",
    "        attn  = self.norm(attn_output + x_skip)\n",
    "        \n",
    "        attn_output = attn.view(batch_size, n_channels, height, width)\n",
    "        \n",
    "        attn_output = self.unbottleneck(attn_output)\n",
    "        return attn_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 64, 128, 128])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example usage\n",
    "n_channels = 64\n",
    "n_heads = 16\n",
    "dim_k = 16\n",
    "n_groups = 8\n",
    "dropout_rate = 0.1\n",
    "reduction_factor = 4\n",
    "group_size = (128**2)//8\n",
    "reduction_factor = 4\n",
    "x = torch.randn(32, n_channels, 128, 128)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "Atten_Block = AttentionBlock(n_channels=n_channels, n_heads = n_heads, dim_k = dim_k, n_groups = n_groups, \n",
    "                         dropout_rate = dropout_rate)\n",
    "\n",
    "output = Atten_Block(x)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "Query_Atten_Block = GroupQueryAttentionBlock(n_channels=n_channels, n_heads = n_heads, dim_k = dim_k, n_groups = n_groups, \n",
    "                         dropout_rate = dropout_rate, group_size = group_size)\n",
    "\n",
    "output = Query_Atten_Block(x)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kdarn\\anaconda3\\envs\\GAPGalaxy\\Lib\\site-packages\\torch\\nn\\modules\\lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 64, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "Conv_Query_Atten_Block = ConvGroupQueryAttentionBlock(n_channels=n_channels, n_heads = n_heads, dim_k = dim_k, n_groups = n_groups, \n",
    "                         dropout_rate = dropout_rate, group_size = group_size, reduction_factor= reduction_factor)\n",
    "\n",
    "output = Conv_Query_Atten_Block(x)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define A Down_Sample Block\n",
    "class Down_Block(nn.Module):\n",
    "    \"\"\"\n",
    "    in_channels = Number of incoming channels\n",
    "    out_channels = Number of outgoing channels\n",
    "    time_channels = Number of time channels\n",
    "    has_attn = Whether the block has an attention mechanism\n",
    "    n_groups = Number of groups in the group normalisation layer\n",
    "    dropout_rate = Dropout Rate\n",
    "    conv_type = The type of convolution block to use\n",
    "    attn_type = The type of attention block to use\n",
    "    downsample = Whether to downsample the image\n",
    "    Pooling = Whether to use pooling or strided convolutions for downsampling\n",
    "    bottleneck_channels = Number of channels in the bottleneck of the Efficient Residual Block\n",
    "    units = Number of units in the SE Block\n",
    "    bottleneck_units = Number of units in the bottleneck of the SE Block\n",
    "    This block is the downsample block used in the attention UNet architecture. It is used to\n",
    "    downsample the image and increase the number of channels in the image. It can incorporate\n",
    "    attention mechanisms and different types of convolution blocks to increase the computational\n",
    "    efficiency of the model.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, time_channels, n_groups,\n",
    "                dropout_rate, conv_type = \"Residual_Block\", attn_type = \"Attention\",\n",
    "                n_heads = None, dim_k = None, group_size = None, downsample = True, \n",
    "                Pooling = True, bottleneck_channels = None, units = None, \n",
    "                reduction_factor = None, bottleneck_units = None):\n",
    "        \n",
    "        super(Down_Block, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.time_channels = time_channels\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.n_groups = n_groups\n",
    "        self.bottleneck_channels = bottleneck_channels\n",
    "        self.units = units\n",
    "        self.bottleneck_units = bottleneck_units\n",
    "        self.conv_type = conv_type\n",
    "        self.attn_type = attn_type\n",
    "        self.Pooling = Pooling\n",
    "        self.downsample = downsample\n",
    "        self.dim_k = dim_k\n",
    "        self.group_size = group_size\n",
    "        self.n_heads = n_heads\n",
    "        self.reduction_factor = reduction_factor\n",
    "\n",
    "        # Define the Down_Block layers\n",
    "        if \"Residual_Block\" in self.conv_type:\n",
    "            self.Conv_Block = Residual_Block(in_channels = in_channels, out_channels = out_channels, \n",
    "                                             time_channels=time_channels, dropout_rate=dropout_rate, \n",
    "                                             n_groups=n_groups)\n",
    "            \n",
    "        if \"Efficient_Residual_Block\" in self.conv_type:\n",
    "            self.Conv_Block = Efficient_Residual_Block(in_channels=in_channels, bottleneck_channels=bottleneck_channels, \n",
    "                                                       time_channels=time_channels, out_channels=out_channels, \n",
    "                                                       dropout_rate=dropout_rate, n_groups=n_groups)\n",
    "            \n",
    "        if \"SqueezeExtraction_Block\" in self.conv_type:\n",
    "            self.Conv_Block = SqueezeExtraction_Block(filters = out_channels, units = units, dropout_rate= dropout_rate, \n",
    "                                                      time_channels= time_channels, units_bottleneck= bottleneck_units, n_groups= n_groups)\n",
    "        if \"ResidualDense_Block\" in self.conv_type:\n",
    "            self.Conv_Block = ResidualDense_Block(in_channels = in_channels, out_channels = out_channels, \n",
    "                                                 time_channels = time_channels, dropout_rate = dropout_rate, n_groups = n_groups)\n",
    "        \n",
    "        if attn_type is not None:\n",
    "            self.has_attn = True\n",
    "            if \"Attention\" in attn_type:\n",
    "                self.Attention = AttentionBlock(n_channels= out_channels, n_heads = n_heads, dim_k = dim_k, n_groups = n_groups, \n",
    "                                                dropout_rate = dropout_rate)\n",
    "            if \"GroupQueryAttention\" in attn_type:\n",
    "                self.Attention = GroupQueryAttentionBlock(n_channels=out_channels, n_heads = n_heads, dim_k = dim_k, n_groups = n_groups, \n",
    "                                                          dropout_rate = dropout_rate, group_size = group_size)\n",
    "            if \"ConvGroupQueryAttention\" in attn_type:\n",
    "                self.Attention = ConvGroupQueryAttentionBlock(n_channels=out_channels, n_heads = n_heads, dim_k = dim_k, n_groups = n_groups, \n",
    "                                                             dropout_rate = dropout_rate, group_size = group_size, reduction_factor = reduction_factor)\n",
    "        else:\n",
    "            self.has_attn = False\n",
    "            self.Attention = None\n",
    "\n",
    "        if self.downsample:\n",
    "            if self.Pooling:\n",
    "                self.Pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "            else:\n",
    "                self.stride = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding = 1, stride=2) \n",
    "\n",
    "    def forward(self, x, t):\n",
    "        x = self.Conv_Block(x, t)\n",
    "        if self.has_attn:\n",
    "            x = self.Attention(x)\n",
    "        \n",
    "        if self.downsample:\n",
    "            before_pool = x\n",
    "            if self.Pooling:\n",
    "                before_pool = x\n",
    "                x = self.Pool(x)\n",
    "            else:\n",
    "                before_pool = x\n",
    "                x = self.stride(x)\n",
    "            \n",
    "            return x, before_pool\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Up_Sample Block\n",
    "class Up_Block(nn.Module):\n",
    "    \"\"\"\n",
    "    in_channels = Number of incoming channels\n",
    "    out_channels = Number of outgoing channels\n",
    "    time_channels = Number of time channels\n",
    "    has_attn = Whether the block has an attention mechanism\n",
    "    n_groups = Number of groups in the group normalisation layer\n",
    "    dropout_rate = Dropout Rate\n",
    "    conv_type = The type of convolution block to use\n",
    "    attn_type = The type of attention block to use\n",
    "    up_sample = Whether to upsample the image.\n",
    "    transpose = Whether to use transpose convolutions or upsample layers for upsampling.\n",
    "    merge_type = The type of merge operation to use for the skip connections.\n",
    "    bottleneck_channels = Number of channels in the bottleneck of the Efficient Residual Block\n",
    "    units = Number of units in the SE Block\n",
    "    bottleneck_units = Number of units in the bottleneck of the SE Block\n",
    "    This block is the upsample block used in the attention UNet architecture. It is used to\n",
    "    upsample the image and decrease the number of channels in the image. It can incorporate\n",
    "    attention mechanisms and different types of convolution blocks to increase the computational\n",
    "    efficiency of the model.\n",
    "    \"\"\" \n",
    "    def __init__(self, in_channels, out_channels, time_channels, n_groups,\n",
    "                dropout_rate, conv_type = \"Residual_Block\", attn_type = \"Attention\",\n",
    "                up_sample = True, transpose = True, merge_type = \"concat\", n_heads = None,\n",
    "                dim_k = None, group_size = None, reduction_factor = None, \n",
    "                bottleneck_channels = None, units = None, bottleneck_units = None):\n",
    "        super(Up_Block, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.time_channels = time_channels\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.n_groups = n_groups\n",
    "        self.bottleneck_channels = bottleneck_channels\n",
    "        self.units = units\n",
    "        self.bottleneck_units = bottleneck_units\n",
    "        self.conv_type = conv_type\n",
    "        self.attn_type = attn_type\n",
    "        self.transpose = transpose\n",
    "        self.merge_type = merge_type\n",
    "        self.up_sample = up_sample\n",
    "        self.dim_k = dim_k\n",
    "        self.group_size = group_size\n",
    "        self.reduction_factor = reduction_factor\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "        # Define the Up_Block layers\n",
    "        if up_sample:\n",
    "            if \"Residual_Block\" in self.conv_type:\n",
    "                self.Conv_Block = Residual_Block(2*in_channels, out_channels=out_channels, time_channels=time_channels, \n",
    "                                                dropout_rate=dropout_rate, n_groups= n_groups)\n",
    "                \n",
    "            if \"Efficient_Residual_Block\" in self.conv_type:\n",
    "                self.Conv_Block = Efficient_Residual_Block(2*in_channels, bottleneck_channels=bottleneck_channels, time_channels= time_channels, \n",
    "                                                       out_channels= out_channels, dropout_rate=dropout_rate, n_groups=n_groups)\n",
    "            \n",
    "            if \"SqueezeExtraction_Block\" in self.conv_type:\n",
    "                self.Conv_Block = SqueezeExtraction_Block(2*in_channels, units = units, dropout_rate= dropout_rate, \n",
    "                                                      time_channels= time_channels, units_bottleneck= bottleneck_units) \n",
    "            \n",
    "            if \"ResidualDense_Block\" in self.conv_type:\n",
    "                self.Conv_Block = ResidualDense_Block(2*in_channels, out_channels= out_channels, \n",
    "                                                  dropout_rate= dropout_rate, time_channels= time_channels, \n",
    "                                                  n_groups= n_groups)\n",
    "                \n",
    "        else:\n",
    "            if \"Residual_Block\" in self.conv_type:\n",
    "                self.Conv_Block = Residual_Block(in_channels, out_channels=out_channels, time_channels=time_channels, \n",
    "                                                dropout_rate=dropout_rate, n_groups= n_groups)\n",
    "                \n",
    "            if \"Efficient_Residual_Block\" in self.conv_type:\n",
    "                self.Conv_Block = Efficient_Residual_Block(in_channels, bottleneck_channels=bottleneck_channels, time_channels= time_channels, \n",
    "                                                       out_channels= out_channels, dropout_rate=dropout_rate, n_groups=n_groups)\n",
    "            \n",
    "            if \"SqueezeExtraction_Block\" in self.conv_type:\n",
    "                self.Conv_Block = SqueezeExtraction_Block(in_channels, units = units, dropout_rate= dropout_rate, \n",
    "                                                      time_channels= time_channels, units_bottleneck= bottleneck_units) \n",
    "            \n",
    "            if \"ResidualDense_Block\" in self.conv_type:\n",
    "                self.Conv_Block = ResidualDense_Block(in_channels, out_channels= out_channels, \n",
    "                                                  dropout_rate= dropout_rate, time_channels= time_channels, \n",
    "                                                  n_groups= n_groups)\n",
    "\n",
    "        \n",
    "        if attn_type is not None:\n",
    "            self.has_attn = True\n",
    "            if \"Attention\" in attn_type:\n",
    "                self.Attention = AttentionBlock(n_channels= out_channels, n_heads = n_heads, dim_k = dim_k, n_groups = n_groups, \n",
    "                                                dropout_rate = dropout_rate)\n",
    "            if \"GroupQueryAttention\" in attn_type:\n",
    "                self.Attention = GroupQueryAttentionBlock(n_channels=out_channels, n_heads = n_heads, dim_k = dim_k, n_groups = n_groups, \n",
    "                                                          dropout_rate = dropout_rate, group_size = group_size)\n",
    "            if \"ConvGroupQueryAttention\" in attn_type:\n",
    "                self.Attention = ConvGroupQueryAttentionBlock(n_channels=out_channels, n_heads = n_heads, dim_k = dim_k, n_groups = n_groups, \n",
    "                                                             dropout_rate = dropout_rate, group_size = group_size, reduction_factor = reduction_factor)\n",
    "        else:\n",
    "            self.has_attn = False\n",
    "            self.Attention = None\n",
    "        \n",
    "        if up_sample:\n",
    "            if self.transpose:\n",
    "                self.Upsample = nn.ConvTranspose2d(in_channels, in_channels, kernel_size=2, stride=2)\n",
    "            else:\n",
    "                self.Upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        \n",
    "    def forward(self, x, before_pool, t):\n",
    "        if self.up_sample:\n",
    "            x = self.Upsample(x)\n",
    "            if \"concat\" in self.merge_type:\n",
    "                x = torch.cat((x, before_pool), 1)\n",
    "            else: \n",
    "                x += before_pool\n",
    "\n",
    "        x = self.Conv_Block(x, t)\n",
    "\n",
    "        if self.has_attn:\n",
    "            x = self.Attention(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiddleBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    in_channels = Number of incoming channels\n",
    "    time_channels = Number of time channels\n",
    "    has_attn = Whether the block has an attention mechanism\n",
    "    n_groups = Number of groups in the group normalisation layer\n",
    "    dropout_rate = Dropout Rate\n",
    "    conv_type = The type of convolution block to use\n",
    "    attn_type = The type of attention block to use\n",
    "    bottleneck_channels = Number of channels in the bottleneck of the Efficient Residual Block\n",
    "    units = Number of units in the SE Block\n",
    "    bottleneck_units = Number of units in the bottleneck of the SE Block\n",
    "    This block is the middle block used in the attention UNet architecture. It is used to\n",
    "    process the image and incorporate attention mechanisms to capture long-range dependencies\n",
    "    in the image. It can incorporate different types of convolution blocks to increase the computational\n",
    "    efficiency of the model.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, time_channels, n_groups,\n",
    "                dropout_rate, conv_type = \"Residual_Block\", attn_type = \"Attention\",\n",
    "                bottleneck_channels = None, bottleneck_units = None, units = None,\n",
    "                n_heads = None, dim_k = None, group_size = None, reduction_factor = None):\n",
    "        super(MiddleBlock, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.time_channels = time_channels\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.n_groups = n_groups\n",
    "        self.bottleneck_channels = bottleneck_channels\n",
    "        self.units = units\n",
    "        self.bottleneck_units = bottleneck_units\n",
    "        self.conv_type = conv_type\n",
    "        self.attn_type = attn_type\n",
    "        self.n_heads = n_heads\n",
    "        self.dim_k = dim_k\n",
    "        self.group_size = group_size\n",
    "        self.reduction_factor = reduction_factor\n",
    "        \n",
    "        # Define the MiddleBlock layers\n",
    "        if \"Residual_Block\" in self.conv_type:\n",
    "            self.Conv_Block_1 = Residual_Block(in_channels = in_channels, out_channels = in_channels, \n",
    "                                             time_channels=time_channels, dropout_rate=dropout_rate, \n",
    "                                             n_groups=n_groups)\n",
    "            \n",
    "            self.Conv_Block_2 = Residual_Block(in_channels = in_channels, out_channels = in_channels, \n",
    "                                             time_channels=time_channels, dropout_rate=dropout_rate, \n",
    "                                             n_groups=n_groups)\n",
    "            \n",
    "        if \"Efficient_Residual_Block\" in self.conv_type:\n",
    "            self.Conv_Block_1 = Efficient_Residual_Block(in_channels=in_channels, bottleneck_channels=bottleneck_channels, \n",
    "                                                       time_channels=time_channels, out_channels=in_channels, \n",
    "                                                       dropout_rate=dropout_rate, n_groups=n_groups)\n",
    "            \n",
    "            self.Conv_Block_2 = Efficient_Residual_Block(in_channels=in_channels, bottleneck_channels=bottleneck_channels, \n",
    "                                                       time_channels=time_channels, out_channels=in_channels, \n",
    "                                                       dropout_rate=dropout_rate, n_groups=n_groups)\n",
    "    \n",
    "        if \"SqueezeExtraction_Block\" in self.conv_type:\n",
    "            self.Conv_Block_1 = SqueezeExtraction_Block(filters = in_channels, units = units, dropout_rate= dropout_rate, \n",
    "                                                      time_channels= time_channels, units_bottleneck= bottleneck_units, n_groups= n_groups)\n",
    "            \n",
    "            self.Conv_Block_2 = SqueezeExtraction_Block(filters = in_channels, units = units, dropout_rate= dropout_rate, \n",
    "                                                      time_channels= time_channels, units_bottleneck= bottleneck_units, n_groups= n_groups)\n",
    "        if \"ResidualDense_Block\" in self.conv_type:\n",
    "            self.Conv_Block_1 = ResidualDense_Block(in_channels = in_channels, out_channels = in_channels, \n",
    "                                                 time_channels = time_channels, dropout_rate = dropout_rate, n_groups = n_groups)\n",
    "            \n",
    "            self.Conv_Block_2 = ResidualDense_Block(in_channels = in_channels, out_channels = in_channels, \n",
    "                                                 time_channels = time_channels, dropout_rate = dropout_rate, n_groups = n_groups)\n",
    "            \n",
    "        if attn_type is not None:\n",
    "            self.has_attn = True\n",
    "            if \"Attention\" in attn_type:\n",
    "                self.Attention = AttentionBlock(n_channels= in_channels, n_heads = n_heads, dim_k = dim_k, n_groups = n_groups, \n",
    "                                                dropout_rate = dropout_rate)\n",
    "            if \"GroupQueryAttention\" in attn_type:\n",
    "                self.Attention = GroupQueryAttentionBlock(n_channels=in_channels, n_heads = n_heads, dim_k = dim_k, n_groups = n_groups, \n",
    "                                                          dropout_rate = dropout_rate, group_size = group_size)\n",
    "            if \"ConvGroupQueryAttention\" in attn_type:\n",
    "                self.Attention = ConvGroupQueryAttentionBlock(n_channels=in_channels, n_heads = n_heads, dim_k = dim_k, n_groups = n_groups, \n",
    "                                                             dropout_rate = dropout_rate, group_size = group_size, reduction_factor = reduction_factor)\n",
    "        else:\n",
    "            self.has_attn = False\n",
    "            self.Attention = None\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        x = self.Conv_Block_1(x, t)\n",
    "        if self.has_attn:\n",
    "            x = self.Attention(x)\n",
    "        x = self.Conv_Block_2(x, t)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionUNet(pL.LightningModule):\n",
    "    \"\"\"\n",
    "    initial_channels = Number of channels to initially project the image into.\n",
    "    channels_list = Number of channels in each layer of the UNet.\n",
    "    blocks_per_channel = Number of blocks per channel in the UNet.\n",
    "    n_groups = Number of groups in the group normalisation layer.\n",
    "    n_heads = Number of heads to use for the multiheaded attention.\n",
    "    dim_k  = The desired dimensionality of the target key and query vectors.\n",
    "    dropout_rate = Dropout Rate.\n",
    "    time_channels = Number of time channels.\n",
    "    bottleneck_channels = Number of channels in the bottleneck of the Efficient Residual Block.\n",
    "    units = Number of units in the SE Block.\n",
    "    bottleneck_units = Number of units in the bottleneck of the SE Block.\n",
    "    has_attn = Whether the block has an attention mechanism.\n",
    "    conv_type = The type of convolution block to use.\n",
    "    attn_type_list = The type of attention block to use.\n",
    "    merge_type = The type of merge operation to use for the skip connections.\n",
    "    maxpsnr = The maximum psnr value in the dataset.\n",
    "    minpsnr = The minimum psnr value in the dataset.\n",
    "    num_timesteps = The number of timesteps in the dataset.\n",
    "    image_channels = The number of channels in the image.\n",
    "    This class defines the Attention UNet architecture. It is a variant of the standard UNet\n",
    "    architecture that incorporates attention mechanisms to capture long-range dependencies \n",
    "    in the image. This architecture is designed to be used in conjunction with the GAP framework\n",
    "    it takes the psnr level of the image as input and uses it to generate the temporal embedding\n",
    "    and then a positional encoding which when combined with the photon count distribution \n",
    "    of the image is used to predict the photon arrival distribution.\n",
    "    \"\"\"\n",
    "    def __init__(self, initial_channels, channels_list, blocks_per_channel, n_groups, n_heads, dim_k, reduction_factor, group_size, dropout_rate, time_channels, \n",
    "                 bottleneck_channels, units, bottleneck_units, conv_type, attn_type_list, merge_type, upsample_type, maxpsnr, minpsnr, \n",
    "                 num_timesteps, middle_attn_type, image_channels = 1):\n",
    "        super(AttentionUNet, self).__init__()\n",
    "\n",
    "        self.initial_channels = initial_channels\n",
    "        self.channels_list = channels_list\n",
    "        self.n_groups = n_groups\n",
    "        self.n_heads = n_heads\n",
    "        self.reduction_factor = reduction_factor\n",
    "        self.group_size = group_size\n",
    "        self.middle_attn_type = middle_attn_type\n",
    "        self.dim_k = dim_k\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.time_channels = time_channels\n",
    "        self.bottleneck_channels = bottleneck_channels\n",
    "        self.bottleneck_units = bottleneck_units\n",
    "        self.blocks_per_channels = blocks_per_channel\n",
    "        self.units = units\n",
    "        self.transpose = upsample_type\n",
    "        self.conv_type = conv_type\n",
    "        self.attn_type_list = attn_type_list\n",
    "        self.merge_type = merge_type\n",
    "        self.depth = len(self.channels_list)\n",
    "        self.maxpsnr = maxpsnr\n",
    "        self.minpsnr = minpsnr\n",
    "        self.num_timesteps = num_timesteps\n",
    "        self.image_channels = image_channels\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # Define the Psnr_to_Timestep function\n",
    "        self.Psnr_Converter = lambda psnr: psnr_to_timestep(psnr, self.maxpsnr, self.minpsnr, self.num_timesteps)\n",
    "\n",
    "        # Define the AttentionUNet layers\n",
    "        self.DownBlocks = []\n",
    "        self.MiddleBlocks = []\n",
    "        self.UpBlocks = []\n",
    "    \n",
    "\n",
    "        self.Image_Projection = nn.LazyConv2d(initial_channels, kernel_size=3, padding=1, stride=1)\n",
    "        self.input_norm = nn.GroupNorm(n_groups, self.initial_channels)\n",
    "        self.input_Mish = Mish()\n",
    "\n",
    "        self.Temporal_Embedding = Temporal_Embedder(initial_channels *4)\n",
    "\n",
    "        for index in range(self.depth):\n",
    "            in_channels = self.initial_channels if index == 0 else self.channels_list[index-1]\n",
    "            out_channels = self.channels_list[index] \n",
    "            attn_type = attn_type_list[index]\n",
    "\n",
    "            for index in range(self.blocks_per_channels):\n",
    "\n",
    "                if index != self.blocks_per_channels -1:\n",
    "                    self.DownBlocks.append(Down_Block(in_channels = in_channels,\n",
    "                        out_channels = in_channels, \n",
    "                        time_channels = initial_channels*4,\n",
    "                        n_groups = n_groups,\n",
    "                        dropout_rate = dropout_rate,\n",
    "                        conv_type = conv_type,\n",
    "                        attn_type = attn_type,\n",
    "                        downsample = False,\n",
    "                        Pooling = True,\n",
    "                        bottleneck_channels = bottleneck_channels,\n",
    "                        units = units,\n",
    "                        bottleneck_units = bottleneck_units,\n",
    "                        n_heads= n_heads,\n",
    "                        group_size = group_size,\n",
    "                        dim_k = dim_k,\n",
    "                        reduction_factor = reduction_factor\n",
    "                    ))\n",
    "\n",
    "                elif index == self.blocks_per_channels - 1:\n",
    "                  self.DownBlocks.append(Down_Block(in_channels = in_channels,\n",
    "                    out_channels = out_channels, \n",
    "                    time_channels = initial_channels*4,\n",
    "                    n_groups = n_groups,\n",
    "                    dropout_rate = dropout_rate,\n",
    "                    conv_type = conv_type,\n",
    "                    attn_type = attn_type,\n",
    "                    downsample = True,\n",
    "                    Pooling = True,\n",
    "                    bottleneck_channels = bottleneck_channels,\n",
    "                    units = units,\n",
    "                    bottleneck_units = bottleneck_units,\n",
    "                    n_heads= n_heads,\n",
    "                    group_size = group_size,\n",
    "                    dim_k = dim_k,\n",
    "                    reduction_factor = reduction_factor\n",
    "                )) \n",
    "                  \n",
    "                     \n",
    "\n",
    "            \n",
    "        self.MiddleBlocks.append(MiddleBlock(in_channels= self.channels_list[-1],\n",
    "                                            time_channels= initial_channels*4,\n",
    "                                            n_groups= n_groups,\n",
    "                                            dropout_rate= dropout_rate,\n",
    "                                            conv_type= conv_type,\n",
    "                                            attn_type= middle_attn_type,\n",
    "                                            bottleneck_channels= bottleneck_channels,\n",
    "                                            units= units,\n",
    "                                            bottleneck_units= bottleneck_units,\n",
    "                                            n_heads= n_heads,\n",
    "                                            group_size = group_size,\n",
    "                                            dim_k = dim_k,\n",
    "                                            reduction_factor = reduction_factor\n",
    "                                            )\n",
    "                )\n",
    "\n",
    "        for index in range(self.depth-2, -1, -1):\n",
    "            in_channels = self.channels_list[index+1]\n",
    "            out_channels = self.channels_list[index]\n",
    "            attn_type = attn_type_list[index]\n",
    "            #print(in_channels, out_channels, attn_type)\n",
    "    \n",
    "            for index in range(self.blocks_per_channels):\n",
    "\n",
    "                if index == 0:\n",
    "                    self.UpBlocks.append(Up_Block(in_channels = in_channels, \n",
    "                                            out_channels= out_channels,\n",
    "                                            time_channels= initial_channels*4,\n",
    "                                            n_groups=n_groups,\n",
    "                                            dropout_rate=dropout_rate,\n",
    "                                            conv_type=conv_type,\n",
    "                                            attn_type=attn_type,\n",
    "                                            up_sample=True,\n",
    "                                            transpose=self.transpose,\n",
    "                                            merge_type=merge_type,\n",
    "                                            bottleneck_channels=bottleneck_channels,\n",
    "                                            units=units,\n",
    "                                            bottleneck_units=bottleneck_units,\n",
    "                                            n_heads= n_heads,\n",
    "                                            group_size = group_size,\n",
    "                                            dim_k = dim_k,\n",
    "                                            reduction_factor = reduction_factor\n",
    "                ))\n",
    "                    \n",
    "                elif index != 0:\n",
    "                    self.UpBlocks.append(Up_Block(in_channels = out_channels, \n",
    "                                            out_channels= out_channels,\n",
    "                                            time_channels= initial_channels*4,\n",
    "                                            n_groups=n_groups,\n",
    "                                            dropout_rate=dropout_rate,\n",
    "                                            conv_type=conv_type,\n",
    "                                            attn_type=attn_type,\n",
    "                                            up_sample=False,\n",
    "                                            transpose=self.transpose,\n",
    "                                            merge_type=merge_type,\n",
    "                                            bottleneck_channels=bottleneck_channels,\n",
    "                                            units=units,\n",
    "                                            bottleneck_units=bottleneck_units,\n",
    "                                            n_heads= n_heads,\n",
    "                                            group_size = group_size,\n",
    "                                            dim_k = dim_k,\n",
    "                                            reduction_factor = reduction_factor\n",
    "                ))\n",
    "            \n",
    "        self.Final_Upsample = Up_Block(\n",
    "            in_channels = out_channels,\n",
    "            out_channels = initial_channels,\n",
    "            time_channels= initial_channels*4,\n",
    "            n_groups=n_groups,\n",
    "            dropout_rate=dropout_rate,\n",
    "            conv_type=conv_type,\n",
    "            attn_type=attn_type,\n",
    "            up_sample=True,\n",
    "            transpose=self.transpose,\n",
    "            merge_type=merge_type,\n",
    "            bottleneck_channels=bottleneck_channels,\n",
    "            units=units,\n",
    "            bottleneck_units=bottleneck_units,\n",
    "            n_heads= n_heads,\n",
    "            group_size = group_size,\n",
    "            dim_k = dim_k,\n",
    "            reduction_factor = reduction_factor\n",
    "            )    \n",
    "            \n",
    "\n",
    "        self.output_norm = nn.GroupNorm(n_groups, self.initial_channels)\n",
    "        self.output_Mish = Mish()\n",
    "        self.Output_Layer = nn.Conv2d(self.initial_channels, self.image_channels, kernel_size=1, stride=1)\n",
    "    \n",
    "        self.DownBlocks = nn.ModuleList(self.DownBlocks)\n",
    "        self.MiddleBlocks = nn.ModuleList(self.MiddleBlocks)\n",
    "        self.UpBlocks = nn.ModuleList(self.UpBlocks)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        psnr = torch.FloatTensor([-40.0])\n",
    "        t = self.Psnr_Converter(psnr)\n",
    "        t = self.Temporal_Embedding(t)\n",
    "        \n",
    "        stack = None\n",
    "        \n",
    "        factor = 10.0\n",
    "        for i in range(self.depth):\n",
    "            scale = x.clone()*(factor**(-i))\n",
    "            scale = torch.sin(scale)\n",
    "            if stack is None:\n",
    "                stack = scale\n",
    "            else:\n",
    "                stack = torch.cat((stack,scale),1)\n",
    "        \n",
    "        x = stack\n",
    "\n",
    "        x = self.Image_Projection(x)\n",
    "        x = self.input_norm(x)\n",
    "        x = self.input_Mish(x)\n",
    "        \n",
    "        Encoder_Skip_Connections = []\n",
    "        for block in self.DownBlocks:\n",
    "            #print(x.shape, \"Downsampling\")\n",
    "            if block.downsample:\n",
    "                x, before_pool = block(x, t)\n",
    "                Encoder_Skip_Connections.append(before_pool)\n",
    "            else:\n",
    "                x = block(x, t)\n",
    "        \n",
    "\n",
    "        for block in self.MiddleBlocks:\n",
    "            x = block(x, t)\n",
    "        \n",
    "        ptr = 0\n",
    "        slow_ptr = 0\n",
    "        Reversed_Encoder_Skip_Connections = Encoder_Skip_Connections[::-1]\n",
    "        while ptr < len(self.UpBlocks):\n",
    "            #print(x.shape, ptr, slow_ptr, before_pool.shape, \"Upsampling\")\n",
    "            before_pool = Reversed_Encoder_Skip_Connections[slow_ptr]\n",
    "            if ptr % self.blocks_per_channels == 0:\n",
    "                x = self.UpBlocks[ptr](x, before_pool, t)\n",
    "                slow_ptr += 1\n",
    "            else:\n",
    "                x = self.UpBlocks[ptr](x, before_pool, t)\n",
    "            ptr += 1\n",
    "        \n",
    "        before_pool = Encoder_Skip_Connections[0]\n",
    "        x = self.Final_Upsample(x, before_pool, t)\n",
    "\n",
    "        x = self.Output_Layer(self.output_Mish(self.output_norm(x)))\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def weight_init(m):\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            init.xavier_normal(m.weight)\n",
    "            init.constant(m.bias, 0)\n",
    "    \n",
    "    def reset_params(self):\n",
    "        for i, m in enumerate(self.modules()):\n",
    "            self.weight_init(m)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(self.parameters(), lr=1e-4)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10)\n",
    "        \n",
    "        return {\n",
    "           'optimizer': optimizer,\n",
    "           'lr_scheduler': scheduler, \n",
    "           'monitor': 'val_loss'\n",
    "        }\n",
    "    \n",
    "    def photonLoss(self,result, target):\n",
    "        expEnergy = torch.exp(result)\n",
    "        perImage =  -torch.mean(result*target, dim =(-1,-2,-3), keepdims = True )\n",
    "        perImage += torch.log(torch.mean(expEnergy, dim =(-1,-2,-3), keepdims = True ))*torch.mean(target, dim =(-1,-2,-3), keepdims = True )\n",
    "        return torch.mean(perImage)\n",
    "    \n",
    "    def MSELoss(self,result, target):\n",
    "        expEnergy = torch.exp(result)\n",
    "        expEnergy /= (torch.mean(expEnergy, dim =(-1,-2,-3), keepdims = True ))\n",
    "        target = target / (torch.mean(target, dim =(-1,-2,-3), keepdims = True ))\n",
    "        return torch.mean((expEnergy-target)**2)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx = None):\n",
    "        img_input, psnr_image, target_img  = batch\n",
    "        psnr = psnr_image.min()\n",
    "        predicted = self.forward(img_input)\n",
    "        train_loss = self.photonLoss(predicted, target_img)\n",
    "        self.log(\"train_loss\", train_loss, on_step = False, on_epoch = True, prog_bar = True, logger = True)\n",
    "        return train_loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx = None):\n",
    "        img_input, psnr_image, target_img = batch\n",
    "        psnr = psnr_image.min()\n",
    "        predicted = self.forward(img_input)\n",
    "        valid_loss = self.photonLoss(predicted, target_img)\n",
    "        self.log(\"val_loss\", valid_loss, on_step = False, on_epoch = True, prog_bar = True, logger = True)\n",
    "        return valid_loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx = None):\n",
    "        img_input, psnr_image, target_img = batch\n",
    "        psnr = psnr_image.min()\n",
    "        predicted = self.forward(img_input)\n",
    "        test_loss = self.photonLoss(predicted, target_img)\n",
    "        self.log(\"test_loss\", test_loss, on_step = False, on_epoch = True, prog_bar = True, logger = True)\n",
    "        return test_loss\n",
    "\n",
    "    def predict(self, x, psnr):\n",
    "        return self.forward(x, psnr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Attention Unet Model\n",
    "\n",
    "# Define the Hyperparameters of the Model:\n",
    "initial_channels = 8\n",
    "image_channels = 1\n",
    "blocks_per_channel = 2\n",
    "n_groups = 8\n",
    "n_heads = 8\n",
    "channels_list = [32, 64, 128, 256, 512]\n",
    "dim_k = 64\n",
    "group_size = 128\n",
    "reduction_factor = 4\n",
    "dropout_rate = 0.1\n",
    "time_channels = 512\n",
    "bottleneck_channels = 64\n",
    "units = 128\n",
    "bottleneck_units = 64\n",
    "has_attn = True\n",
    "conv_type = \"Residual_Block\"\n",
    "attn_type_list = [None, None, None, None, None]\n",
    "middle_attn_type = \"Attention\"\n",
    "merge_type = \"concat\"\n",
    "maxpsnr = -5.0\n",
    "minpsnr = -40.0\n",
    "num_timesteps = 1024\n",
    "\n",
    "# Define the Attention Network:\n",
    "AttnUNet = AttentionUNet(\n",
    "    initial_channels = initial_channels,\n",
    "    channels_list = channels_list,\n",
    "    blocks_per_channel = blocks_per_channel,\n",
    "    n_groups = n_groups,\n",
    "    n_heads = n_heads,\n",
    "    dim_k = dim_k,\n",
    "    dropout_rate = dropout_rate,\n",
    "    time_channels = time_channels,\n",
    "    bottleneck_channels = bottleneck_channels,\n",
    "    units = units,\n",
    "    bottleneck_units= bottleneck_units,\n",
    "    conv_type = conv_type,\n",
    "    attn_type_list = attn_type_list,\n",
    "    merge_type = merge_type,\n",
    "    maxpsnr = maxpsnr,\n",
    "    minpsnr = minpsnr,\n",
    "    num_timesteps = num_timesteps,\n",
    "    image_channels = image_channels,\n",
    "    reduction_factor= reduction_factor,\n",
    "    group_size= group_size,\n",
    "    middle_attn_type= middle_attn_type,\n",
    "    upsample_type = \"transpose\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AttentionUNet(\n",
       "  (Image_Projection): LazyConv2d(0, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (input_norm): GroupNorm(8, 8, eps=1e-05, affine=True)\n",
       "  (input_Mish): Mish()\n",
       "  (Temporal_Embedding): Temporal_Embedder(\n",
       "    (Linear_1): Linear(in_features=8, out_features=32, bias=True)\n",
       "    (Linear_2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (Mish_1): Mish()\n",
       "    (Mish_2): Mish()\n",
       "  )\n",
       "  (Final_Upsample): Up_Block(\n",
       "    (Conv_Block): Residual_Block(\n",
       "      (time_embedding): Linear(in_features=32, out_features=8, bias=True)\n",
       "      (conv1): Conv2d(64, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv3): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (GroupNorm_1): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "      (GroupNorm_2): GroupNorm(8, 8, eps=1e-05, affine=True)\n",
       "      (Batch_Norm_1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "      (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "      (Mish_1): Mish()\n",
       "      (Mish_2): Mish()\n",
       "      (Mish_3): Mish()\n",
       "    )\n",
       "    (Upsample): ConvTranspose2d(32, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "  )\n",
       "  (output_norm): GroupNorm(8, 8, eps=1e-05, affine=True)\n",
       "  (output_Mish): Mish()\n",
       "  (Output_Layer): Conv2d(8, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (DownBlocks): ModuleList(\n",
       "    (0): Down_Block(\n",
       "      (Conv_Block): Residual_Block(\n",
       "        (time_embedding): Linear(in_features=32, out_features=8, bias=True)\n",
       "        (conv1): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv3): Conv2d(8, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (GroupNorm_1): GroupNorm(8, 8, eps=1e-05, affine=True)\n",
       "        (GroupNorm_2): GroupNorm(8, 8, eps=1e-05, affine=True)\n",
       "        (Batch_Norm_1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "        (Mish_1): Mish()\n",
       "        (Mish_2): Mish()\n",
       "        (Mish_3): Mish()\n",
       "      )\n",
       "    )\n",
       "    (1): Down_Block(\n",
       "      (Conv_Block): Residual_Block(\n",
       "        (time_embedding): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (conv1): Conv2d(8, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv3): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (GroupNorm_1): GroupNorm(8, 8, eps=1e-05, affine=True)\n",
       "        (GroupNorm_2): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "        (Batch_Norm_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "        (Mish_1): Mish()\n",
       "        (Mish_2): Mish()\n",
       "        (Mish_3): Mish()\n",
       "      )\n",
       "      (Pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (2): Down_Block(\n",
       "      (Conv_Block): Residual_Block(\n",
       "        (time_embedding): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (GroupNorm_1): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "        (GroupNorm_2): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "        (Batch_Norm_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "        (Mish_1): Mish()\n",
       "        (Mish_2): Mish()\n",
       "        (Mish_3): Mish()\n",
       "      )\n",
       "    )\n",
       "    (3): Down_Block(\n",
       "      (Conv_Block): Residual_Block(\n",
       "        (time_embedding): Linear(in_features=32, out_features=64, bias=True)\n",
       "        (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv3): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (GroupNorm_1): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "        (GroupNorm_2): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "        (Batch_Norm_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "        (Mish_1): Mish()\n",
       "        (Mish_2): Mish()\n",
       "        (Mish_3): Mish()\n",
       "      )\n",
       "      (Pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (4): Down_Block(\n",
       "      (Conv_Block): Residual_Block(\n",
       "        (time_embedding): Linear(in_features=32, out_features=64, bias=True)\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (GroupNorm_1): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "        (GroupNorm_2): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "        (Batch_Norm_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "        (Mish_1): Mish()\n",
       "        (Mish_2): Mish()\n",
       "        (Mish_3): Mish()\n",
       "      )\n",
       "    )\n",
       "    (5): Down_Block(\n",
       "      (Conv_Block): Residual_Block(\n",
       "        (time_embedding): Linear(in_features=32, out_features=128, bias=True)\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv3): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (GroupNorm_1): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "        (GroupNorm_2): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "        (Batch_Norm_1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "        (Mish_1): Mish()\n",
       "        (Mish_2): Mish()\n",
       "        (Mish_3): Mish()\n",
       "      )\n",
       "      (Pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (6): Down_Block(\n",
       "      (Conv_Block): Residual_Block(\n",
       "        (time_embedding): Linear(in_features=32, out_features=128, bias=True)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (GroupNorm_1): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "        (GroupNorm_2): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "        (Batch_Norm_1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "        (Mish_1): Mish()\n",
       "        (Mish_2): Mish()\n",
       "        (Mish_3): Mish()\n",
       "      )\n",
       "    )\n",
       "    (7): Down_Block(\n",
       "      (Conv_Block): Residual_Block(\n",
       "        (time_embedding): Linear(in_features=32, out_features=256, bias=True)\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (GroupNorm_1): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "        (GroupNorm_2): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
       "        (Batch_Norm_1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "        (Mish_1): Mish()\n",
       "        (Mish_2): Mish()\n",
       "        (Mish_3): Mish()\n",
       "      )\n",
       "      (Pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (8): Down_Block(\n",
       "      (Conv_Block): Residual_Block(\n",
       "        (time_embedding): Linear(in_features=32, out_features=256, bias=True)\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (GroupNorm_1): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
       "        (GroupNorm_2): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
       "        (Batch_Norm_1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "        (Mish_1): Mish()\n",
       "        (Mish_2): Mish()\n",
       "        (Mish_3): Mish()\n",
       "      )\n",
       "    )\n",
       "    (9): Down_Block(\n",
       "      (Conv_Block): Residual_Block(\n",
       "        (time_embedding): Linear(in_features=32, out_features=512, bias=True)\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (GroupNorm_1): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
       "        (GroupNorm_2): GroupNorm(8, 512, eps=1e-05, affine=True)\n",
       "        (Batch_Norm_1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "        (Mish_1): Mish()\n",
       "        (Mish_2): Mish()\n",
       "        (Mish_3): Mish()\n",
       "      )\n",
       "      (Pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "  )\n",
       "  (MiddleBlocks): ModuleList(\n",
       "    (0): MiddleBlock(\n",
       "      (Conv_Block_1): Residual_Block(\n",
       "        (time_embedding): Linear(in_features=32, out_features=512, bias=True)\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (GroupNorm_1): GroupNorm(8, 512, eps=1e-05, affine=True)\n",
       "        (GroupNorm_2): GroupNorm(8, 512, eps=1e-05, affine=True)\n",
       "        (Batch_Norm_1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "        (Mish_1): Mish()\n",
       "        (Mish_2): Mish()\n",
       "        (Mish_3): Mish()\n",
       "      )\n",
       "      (Conv_Block_2): Residual_Block(\n",
       "        (time_embedding): Linear(in_features=32, out_features=512, bias=True)\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv3): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (GroupNorm_1): GroupNorm(8, 512, eps=1e-05, affine=True)\n",
       "        (GroupNorm_2): GroupNorm(8, 512, eps=1e-05, affine=True)\n",
       "        (Batch_Norm_1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "        (Mish_1): Mish()\n",
       "        (Mish_2): Mish()\n",
       "        (Mish_3): Mish()\n",
       "      )\n",
       "      (Attention): AttentionBlock(\n",
       "        (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "        (output): Linear(in_features=512, out_features=512, bias=True)\n",
       "        (norm): GroupNorm(8, 512, eps=1e-05, affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (UpBlocks): ModuleList(\n",
       "    (0): Up_Block(\n",
       "      (Conv_Block): Residual_Block(\n",
       "        (time_embedding): Linear(in_features=32, out_features=256, bias=True)\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv3): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (GroupNorm_1): GroupNorm(8, 1024, eps=1e-05, affine=True)\n",
       "        (GroupNorm_2): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
       "        (Batch_Norm_1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "        (Mish_1): Mish()\n",
       "        (Mish_2): Mish()\n",
       "        (Mish_3): Mish()\n",
       "      )\n",
       "      (Upsample): ConvTranspose2d(512, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "    (1): Up_Block(\n",
       "      (Conv_Block): Residual_Block(\n",
       "        (time_embedding): Linear(in_features=32, out_features=256, bias=True)\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv3): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (GroupNorm_1): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
       "        (GroupNorm_2): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
       "        (Batch_Norm_1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "        (Mish_1): Mish()\n",
       "        (Mish_2): Mish()\n",
       "        (Mish_3): Mish()\n",
       "      )\n",
       "    )\n",
       "    (2): Up_Block(\n",
       "      (Conv_Block): Residual_Block(\n",
       "        (time_embedding): Linear(in_features=32, out_features=128, bias=True)\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv3): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (GroupNorm_1): GroupNorm(8, 512, eps=1e-05, affine=True)\n",
       "        (GroupNorm_2): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "        (Batch_Norm_1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "        (Mish_1): Mish()\n",
       "        (Mish_2): Mish()\n",
       "        (Mish_3): Mish()\n",
       "      )\n",
       "      (Upsample): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "    (3): Up_Block(\n",
       "      (Conv_Block): Residual_Block(\n",
       "        (time_embedding): Linear(in_features=32, out_features=128, bias=True)\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (GroupNorm_1): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "        (GroupNorm_2): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "        (Batch_Norm_1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "        (Mish_1): Mish()\n",
       "        (Mish_2): Mish()\n",
       "        (Mish_3): Mish()\n",
       "      )\n",
       "    )\n",
       "    (4): Up_Block(\n",
       "      (Conv_Block): Residual_Block(\n",
       "        (time_embedding): Linear(in_features=32, out_features=64, bias=True)\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv3): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (GroupNorm_1): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
       "        (GroupNorm_2): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "        (Batch_Norm_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "        (Mish_1): Mish()\n",
       "        (Mish_2): Mish()\n",
       "        (Mish_3): Mish()\n",
       "      )\n",
       "      (Upsample): ConvTranspose2d(128, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "    (5): Up_Block(\n",
       "      (Conv_Block): Residual_Block(\n",
       "        (time_embedding): Linear(in_features=32, out_features=64, bias=True)\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (GroupNorm_1): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "        (GroupNorm_2): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
       "        (Batch_Norm_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "        (Mish_1): Mish()\n",
       "        (Mish_2): Mish()\n",
       "        (Mish_3): Mish()\n",
       "      )\n",
       "    )\n",
       "    (6): Up_Block(\n",
       "      (Conv_Block): Residual_Block(\n",
       "        (time_embedding): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (conv1): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv3): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (GroupNorm_1): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
       "        (GroupNorm_2): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "        (Batch_Norm_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "        (Mish_1): Mish()\n",
       "        (Mish_2): Mish()\n",
       "        (Mish_3): Mish()\n",
       "      )\n",
       "      (Upsample): ConvTranspose2d(64, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "    (7): Up_Block(\n",
       "      (Conv_Block): Residual_Block(\n",
       "        (time_embedding): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (conv3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (GroupNorm_1): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "        (GroupNorm_2): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
       "        (Batch_Norm_1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "        (Mish_1): Mish()\n",
       "        (Mish_2): Mish()\n",
       "        (Mish_3): Mish()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AttnUNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GAPGalaxy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
